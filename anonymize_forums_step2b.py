# Apply pre-trained machine learning models to decide if possible names are indeed names or not
import argparse

import joblib
import pandas as pd
from sklearn import metrics

argparser = argparse.ArgumentParser(
    description='Apply existing machine learning models to a dataset of possible names to predict '
                'if each one is a name or not')
argparser.add_argument('input_filename', type=str,
                       help='Path to a file generated by step 2a (i.e., a list of possible names '
                       'with features)')
argparser.add_argument('output_filename', type=str,
                       help='Output CSV filename with predicted names for use in step 3')
argparser.add_argument('--predictions-file', type=str, metavar='CSV_FILENAME',
                       help='Output CSV filename where all predictions will be written, including '
                       'probabilities and negative cases (useful for measuring accuracy)')
args = argparser.parse_args()

print('Loading data')
df = pd.read_csv(args.input_filename, encoding='utf-8', na_filter=False)
# Specifying the features. This is done since the ET and NN models were not trained on the same features.
# Removing features that were not used for the training of the Extra Trees Model
features_et = [f for f in df if f not in ['possible_name', 'is_name', 'multi_word_name_original', 'first_index_in_post', 'first_post_length_words']]
# Removing features that were not use for the training of the Neural Net Modl
features_nn = [f for f in df if f not in ['possible_name', 'is_name', 'multi_word_name_original', 'avg_capital_letters_count', 'word_freq_ratio', 'prop_sentence_end', 'avg_index_in_post', 'vowel_count', 'avg_post_length_words']]
print('Found ' + str(len(df.columns)) + ' features, ' + str(len(df)) + ' instances')
new_et_X = df[features_et].values
new_nn_X = df[features_nn].values

print('\nLoading and applying Extra-Trees model')
m = joblib.load('new_model_et.pkl')
print(m)
df.insert(1, 'extratrees_pred', m.predict_proba(new_et_X).T[1])

print('\nLoading and applying DNN model')
m = joblib.load('holdout_model_nn.pkl')
print(m)
df.insert(2, 'nn_pred', m.predict_proba(new_nn_X).T[1])

print('\nSaving results')
# Insert predictions
df.insert(3, 'fusion_pred', df.extratrees_pred * .5 + df.nn_pred * .5)
et_threshold = 1 / 3
et_pred_rate = sum(df.extratrees_pred < et_threshold) / len(df)
nn_threshold = df.nn_pred.quantile(et_pred_rate)
fusion_threshold = df.fusion_pred.quantile(et_pred_rate)
df.insert(1, 'pred_is_name', (df.fusion_pred >= fusion_threshold).astype(int))
# Replace multi-word names (which were earlier concatenated) with their original values
multi_word_names = df[df.multi_word_name_original != ''].multi_word_name_original
df.loc[multi_word_names.index, 'possible_name'] = multi_word_names
# Save
df.loc[df.pred_is_name == 1, ['possible_name', 'occurrences', 'fusion_pred']] \
    .rename(columns={'fusion_pred': 'probability'}) \
    .sort_values('occurrences', ascending=False).to_csv(args.output_filename, index=False)
if args.predictions_file:
    df.to_csv(args.predictions_file, index=False)

# If ground truth was in the input file, calculate some metrics
if 'is_name' in df.columns and sum(df.is_name != '') > 0:
    df = df[df.is_name != '']
    df.is_name = df.is_name.astype(int)
    print('\n--- Extra-Trees')
    print('Threshold:\t', et_threshold)
    print('AUC:\t\t', metrics.roc_auc_score(df.is_name, df.extratrees_pred))
    print('Kappa:\t\t', metrics.cohen_kappa_score(df.is_name, df.extratrees_pred > et_threshold))
    print('Accuracy:\t', metrics.accuracy_score(df.is_name, df.extratrees_pred > et_threshold))
    print('\n--- Neural net')
    print('Threshold:\t', nn_threshold)
    print('AUC:\t\t', metrics.roc_auc_score(df.is_name, df.nn_pred))
    print('Kappa:\t\t', metrics.cohen_kappa_score(df.is_name, df.nn_pred > nn_threshold))
    print('Accuracy:\t', metrics.accuracy_score(df.is_name, df.nn_pred > nn_threshold))
    print('\n--- Fusion')
    print('Threshold:\t', fusion_threshold)
    print('AUC:\t\t', metrics.roc_auc_score(df.is_name, df.fusion_pred))
    print('Kappa:\t\t', metrics.cohen_kappa_score(df.is_name, df.fusion_pred > fusion_threshold))
    print('Accuracy:\t', metrics.accuracy_score(df.is_name, df.fusion_pred > fusion_threshold))
